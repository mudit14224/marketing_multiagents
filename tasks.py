# Imports
from crewai import Task
from pydantic import BaseModel, Field, EmailStr
from typing import Optional, List
import json

# Using Pydantic for structured output
class Queries(BaseModel):
    queries: list[str] = Field(..., title="List of queries generated by the agent.")

# Pydantic for the final consolidation of search results
class ContactInfo(BaseModel):
    name: str
    role_in_company: str
    email_address: Optional[EmailStr] = Field(None, alias='email')
    linkedin: Optional[str] = None
    phone_no: Optional[str] = None

class Tasks:
    def __init__(self, information_specialist, search_query_generator):
        self.information_specialist = information_specialist
        self.search_query_generator = search_query_generator

    def create_query_tasks(self):
        scrape_task = Task(
            description="""Scrape and extract all the relevant information about the company.""",
            agent=self.information_specialist,
            expected_output="""All the details about the {client} in a concise summary that can be used to build search queries based on the 
            search criteria of {search_criteria} to find similar companies.""")

        generate_search_query_task = Task(
        description="""Generate succinct search queries based on the provided criteria: {search_criteria} and 
        information gathered by the Information Specialist. The each query must include all of the search criteria. Generate at max 4 queries.""",
        expected_output='A Python list of strings, where each string is a search query.',
        agent=self.search_query_generator,
        output_json = Queries
        )

        return scrape_task, generate_search_query_task

    def create_search_tasks(self, create_researcher_agent, consolidator, search_queries):
        search_tasks = [
            Task(
                description=f"Search the internet using the query: '{query}' to find similar companies.",
                agent=create_researcher_agent(query),
                expected_output=f"A list of potential companies along with their website links found using the query: '{query}'"
            ) for query in search_queries
        ]

        # Define the consolidate results task
        consolidate_results_task = Task(
            description="Consolidate the list of potential companies from the researcher agents into a final list.",
            agent=consolidator,
            expected_output="A final list of potential companies including brief descriptions and website links"
        )

        return search_tasks, consolidate_results_task
    

class ContactSearchTasks: 
    def __init__(self, search_agent, scraper_agent, consolidator):
        self.search_agent = search_agent
        self.scraper_agent = scraper_agent
        self.consolidator = consolidator

    # Output function 
    def consolidation_task_function(self, results: List[dict]) -> str:
        contacts = [ContactInfo(**result) for result in results]
        
        # Convert to JSON
        json_output = [contact.model_dump(by_alias=True) for contact in contacts]
        return json.dump(json_output, indent=2)


    def create_tasks(self):
        # Contact Search Task 
        contact_search_task = Task(
            description=(
                "Use online resources to identify potential websites, LinkedIn profiles, "
                "and other online platforms where contact information of key individuals "
                "within {client}'s organization can be found. Focus on finding members "
                "of their marketing team or other relevant stakeholders. Your final list "
                "should include URLs or online resources where contact information might "
                "be available. Use general queries to search for information."

            ),
            expected_output=(
                "A list of at most 5 URLs or online resources where contact information "
                "of key individuals from {client} might be available. Ensure the sources "
                "are relevant and up-to-date."
            ),
            agent=self.search_agent
        )

        # Web scraping Task
        web_scraping_task = Task(
            description=(
                "Scrape the provided URLs or online resources to extract contact details "
                "such as email addresses, LinkedIn and Phone no. profiles of key "
                "individuals within {client}'s organization. Ensure the information is "
                "accurate and relevant to the marketing team or other relevant stakeholders."
            ),
            expected_output=(
                "A detailed list of contact information extracted from the provided URLs. "
                "Include names, email addresses, LinkedIn profiles and Phone no. "
            ),
            agent=self.scraper_agent
        )

        consolidation_task = Task(
            description=(
                "Combine all the contact information gathered by the scraper agents into a final, organized list of relevant contacts. "
                "The output should be formatted as a JSON file with the fields: Name, Role in company, Email address, LinkedIn and Phone no. "
                "Leave any of Email address, LinkedIn or Phone no. empty if the information is not found."
                "Note: Do not generate Linkedin URLs, Email Addresses or Phone no. on your own. Just leave the field empty if not found."
                "Note: Do not generate fake people like John Doe if information not found. Simply say that No information found."
            ),
            expected_output=(
                "A JSON object containing the consolidated list of contact information. The fields should include: Name, Role in company, Email address, LinkedIn and Phone no."
            ),
            agent = self.consolidator, 
            output_function = self.consolidation_task_function,
        )

        return contact_search_task, web_scraping_task, consolidation_task